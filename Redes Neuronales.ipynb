{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdanMDG/IA-Metodos-de-clasific/blob/main/Redes%20Neuronales.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPL3BOAj5eKm"
      },
      "source": [
        "#1) Redes Neuronales\n",
        "Desarrollo de una red neuronal para reconocimiento de imagenes.\n",
        "Para ello, vamos a trabajar con un dataset provisto por keras: CIFAR10.\n",
        "Este consta de 60000 imágenes en color de 32x32 en 10 clases, con 6000 imágenes por clase. Hay 50000 imágenes de entrenamiento y 10000 imágenes de prueba.\n",
        "Cada imagen representa diferentes tipos de transportes o animales especificos detallados en la siguiente lista:\n",
        "\n",
        "                                0. Airplane\n",
        "                                1. Automobile\n",
        "                                2. Bird\n",
        "                                3. Cat\n",
        "                                4. Beer\n",
        "                                5. Dog\n",
        "                                6. Frog\n",
        "                                7. Horse\n",
        "                                8. Ship\n",
        "                                9. Truck\n",
        "\n",
        "Los valores de los píxeles oscilan entre 0 y 255, indicando la luminosidad de estos(valores mas grandes indican mayor oscuridad).\n",
        "\n",
        "Este dataset va a ser utilizado para reconocer ciertos objetos detallados anteriormente en imagenes, para esto, vamos a utilizar 3 redes neuronales con diferentes arquitecturas.\n",
        "\n",
        "### Paso 1: Importamos librerías y cargar dataset\n",
        "En primer lugar, vamos a importar todas las librerías que utilizaremos en este ejercicio, luego vamos a cargar en memoria el dataset, obteniendo el dataset de entrenamiento y el de testeo y, además, vamos a imprimir sus dimensiones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uy7U0KoiOeHY"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "# Acá deben importar el dataset elegido en el caso de que esté en Keras\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k096yvo2_l6H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9094ed7-78a8-435c-83f1-15d69819bf0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 2s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZEvocAS_pCB",
        "outputId": "a3b84890-2598-446f-8484-bd8ccb5a0615"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cifar10 Dataset Shape:\n",
            "X_train: (50000, 32, 32, 3)\n",
            "Y_train: (50000, 1)\n",
            "X_test:  (10000, 32, 32, 3)\n",
            "Y_test:  (10000, 1)\n"
          ]
        }
      ],
      "source": [
        "print('Cifar10 Dataset Shape:')\n",
        "print('X_train: ' + str(x_train.shape))\n",
        "print('Y_train: ' + str(y_train.shape))\n",
        "print('X_test:  '  + str(x_test.shape))\n",
        "print('Y_test:  '  + str(y_test.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90uNGWXNDkai"
      },
      "source": [
        "### Paso 2: Normalizamos el dataset\n",
        "En este paso vamos a normalizar el dataset. Recordemos que los valores de los pixeles van entre 0-255, es por ello que para la normalización simplemente dividimos los dataset de entrenamiento y testeo por 255."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wzxRggEZDq69"
      },
      "outputs": [],
      "source": [
        "x_train, x_test = x_train/255.0, x_test/255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcZCRgGDDtp9"
      },
      "source": [
        "### Paso 3: Creamos el modelo en Keras\n",
        "Vamos a comenzar creando el primer modelo en Keras muy simple:\n",
        "- Como el dataset consiste de imagenes, debemos utilizar una layer Flatten para aplanar los datos\n",
        "- Vamos a utilizar 3 layers ocultas con activación ReLU ya que son las mas rapidas y su funcionamiento final va a ser similar a las demas, con 40 y 20 neuronas.\n",
        "- Luego agregamos una layer de salida con activación softmax, la cual tendrá 10 neuronas (una por cada tipo del dataset)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WimxOqYcDwo7"
      },
      "outputs": [],
      "source": [
        "#3 redes neuronales con diferente arquitectura. Es importante utilizar distinta cantidad de layers densas (fully connected) y de neuronas en cada una de ellas.\n",
        "\n",
        "primer_modelo = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(40, activation='relu'),\n",
        "    tf.keras.layers.Dense(20, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btH4e9jqGpNu"
      },
      "source": [
        "### Paso 4: Compilamos el modelo\n",
        "Para compilar el modelo utilizamos el optimizador Adam, la función de costo Sparse Categorical Cross Entropy y como metrica de evaluacion Accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYM3IUP6GqU4"
      },
      "outputs": [],
      "source": [
        "primer_modelo.compile(optimizer=\"adam\",\n",
        "              loss=SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSg9_D0mJiCn"
      },
      "source": [
        "### Paso 5: Entrenamos el modelo\n",
        "Ahora que tenemos el modelo creado y compilado, lo que resta es ajustar el modelo a los datos, es decir, entrenar el modelo con el dataset de entrenamiento. Para ello usamos la función .fit() a la cual le pasamos como argumento el dataset de entrenamiento y la cantidad de epochs (cantidad de veces que el algoritmo va a abrir el dataset).\n",
        "\n",
        "Probamos con 10 epochs para ver como se comporta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yX0SGX1MJkqe",
        "outputId": "b6cb08b0-6690-40bb-f8da-7459b858063c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 8s 4ms/step - loss: 1.9982 - accuracy: 0.2571\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.8211 - accuracy: 0.3345\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.7708 - accuracy: 0.3585\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.7370 - accuracy: 0.3736\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.7194 - accuracy: 0.3813\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6994 - accuracy: 0.3861\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.6869 - accuracy: 0.3907\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6737 - accuracy: 0.3965\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.6698 - accuracy: 0.3973\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6585 - accuracy: 0.4005\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7bf5b12b2950>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "primer_modelo.fit(x_train, y_train, epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTt8hT4ULIN3"
      },
      "source": [
        "En la primer Red Neuronal se observa que con 10 Epoch la precision converge en 40%, a continuacion probaremos con mas Epochs para ver si mejora.\n",
        "Epochs de 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3bJ_QeZLngW",
        "outputId": "5f90e6ec-bd07-4611-8f1d-30f85428bfaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.6545 - accuracy: 0.4031\n",
            "Epoch 2/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6481 - accuracy: 0.4031\n",
            "Epoch 3/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.6428 - accuracy: 0.4084\n",
            "Epoch 4/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6410 - accuracy: 0.4075\n",
            "Epoch 5/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.6313 - accuracy: 0.4116\n",
            "Epoch 6/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6315 - accuracy: 0.4101\n",
            "Epoch 7/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.6276 - accuracy: 0.4119\n",
            "Epoch 8/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.6200 - accuracy: 0.4132\n",
            "Epoch 9/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.6190 - accuracy: 0.4163\n",
            "Epoch 10/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6129 - accuracy: 0.4182\n",
            "Epoch 11/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.6154 - accuracy: 0.4148\n",
            "Epoch 12/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6108 - accuracy: 0.4171\n",
            "Epoch 13/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.6070 - accuracy: 0.4184\n",
            "Epoch 14/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6067 - accuracy: 0.4201\n",
            "Epoch 15/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.6046 - accuracy: 0.4202\n",
            "Epoch 16/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6016 - accuracy: 0.4209\n",
            "Epoch 17/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.5982 - accuracy: 0.4210\n",
            "Epoch 18/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5974 - accuracy: 0.4223\n",
            "Epoch 19/20\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.5949 - accuracy: 0.4235\n",
            "Epoch 20/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5928 - accuracy: 0.4247\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7bf5b4b5e4a0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "primer_modelo.fit(x_train, y_train, epochs=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2GDZlQ6MsYx"
      },
      "source": [
        "Se observa un comportamiento similar ya que converge en 42%, vamos a probar por ultimo con un Epoch mas grande y si se comporta igual vamos a probar con otro modelo distinto.\n",
        "Epoch = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fR-3E0gPNX0W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adf08845-4375-4850-bc7a-da117b1b6ddc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.5892 - accuracy: 0.4249\n",
            "Epoch 2/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5882 - accuracy: 0.4245\n",
            "Epoch 3/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.5863 - accuracy: 0.4262\n",
            "Epoch 4/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5842 - accuracy: 0.4265\n",
            "Epoch 5/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.5840 - accuracy: 0.4279\n",
            "Epoch 6/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.5803 - accuracy: 0.4280\n",
            "Epoch 7/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5783 - accuracy: 0.4302\n",
            "Epoch 8/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.5794 - accuracy: 0.4296\n",
            "Epoch 9/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.5760 - accuracy: 0.4285\n",
            "Epoch 10/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5756 - accuracy: 0.4291\n",
            "Epoch 11/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5727 - accuracy: 0.4332\n",
            "Epoch 12/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5719 - accuracy: 0.4316\n",
            "Epoch 13/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5724 - accuracy: 0.4316\n",
            "Epoch 14/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.5682 - accuracy: 0.4336\n",
            "Epoch 15/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5665 - accuracy: 0.4338\n",
            "Epoch 16/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.5661 - accuracy: 0.4344\n",
            "Epoch 17/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.5642 - accuracy: 0.4340\n",
            "Epoch 18/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5635 - accuracy: 0.4351\n",
            "Epoch 19/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5653 - accuracy: 0.4347\n",
            "Epoch 20/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5630 - accuracy: 0.4347\n",
            "Epoch 21/100\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 1.5612 - accuracy: 0.4348\n",
            "Epoch 22/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5611 - accuracy: 0.4333\n",
            "Epoch 23/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5597 - accuracy: 0.4350\n",
            "Epoch 24/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5625 - accuracy: 0.4342\n",
            "Epoch 25/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.5588 - accuracy: 0.4345\n",
            "Epoch 26/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.5589 - accuracy: 0.4334\n",
            "Epoch 27/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.5538 - accuracy: 0.4376\n",
            "Epoch 28/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5552 - accuracy: 0.4355\n",
            "Epoch 29/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5547 - accuracy: 0.4390\n",
            "Epoch 30/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5536 - accuracy: 0.4366\n",
            "Epoch 31/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5535 - accuracy: 0.4377\n",
            "Epoch 32/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5532 - accuracy: 0.4374\n",
            "Epoch 33/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5529 - accuracy: 0.4356\n",
            "Epoch 34/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5532 - accuracy: 0.4384\n",
            "Epoch 35/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.5526 - accuracy: 0.4378\n",
            "Epoch 36/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.5501 - accuracy: 0.4390\n",
            "Epoch 37/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5499 - accuracy: 0.4389\n",
            "Epoch 38/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5472 - accuracy: 0.4403\n",
            "Epoch 39/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5483 - accuracy: 0.4373\n",
            "Epoch 40/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5461 - accuracy: 0.4405\n",
            "Epoch 41/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.5454 - accuracy: 0.4407\n",
            "Epoch 42/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.5452 - accuracy: 0.4403\n",
            "Epoch 43/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5475 - accuracy: 0.4408\n",
            "Epoch 44/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.5434 - accuracy: 0.4400\n",
            "Epoch 45/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5433 - accuracy: 0.4428\n",
            "Epoch 46/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5442 - accuracy: 0.4402\n",
            "Epoch 47/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5412 - accuracy: 0.4424\n",
            "Epoch 48/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.5434 - accuracy: 0.4401\n",
            "Epoch 49/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5422 - accuracy: 0.4425\n",
            "Epoch 50/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5421 - accuracy: 0.4430\n",
            "Epoch 51/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5408 - accuracy: 0.4442\n",
            "Epoch 52/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.5433 - accuracy: 0.4442\n",
            "Epoch 53/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5401 - accuracy: 0.4412\n",
            "Epoch 54/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.5398 - accuracy: 0.4425\n",
            "Epoch 55/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5391 - accuracy: 0.4432\n",
            "Epoch 56/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.5380 - accuracy: 0.4432\n",
            "Epoch 57/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.5390 - accuracy: 0.4425\n",
            "Epoch 58/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.5352 - accuracy: 0.4458\n",
            "Epoch 59/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5356 - accuracy: 0.4438\n",
            "Epoch 60/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.5391 - accuracy: 0.4444\n",
            "Epoch 61/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5379 - accuracy: 0.4446\n",
            "Epoch 62/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.5361 - accuracy: 0.4434\n",
            "Epoch 63/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5358 - accuracy: 0.4455\n",
            "Epoch 64/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.5345 - accuracy: 0.4443\n",
            "Epoch 65/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5338 - accuracy: 0.4456\n",
            "Epoch 66/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.5330 - accuracy: 0.4454\n",
            "Epoch 67/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5342 - accuracy: 0.4457\n",
            "Epoch 68/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.5317 - accuracy: 0.4456\n",
            "Epoch 69/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5323 - accuracy: 0.4470\n",
            "Epoch 70/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.5335 - accuracy: 0.4448\n",
            "Epoch 71/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5330 - accuracy: 0.4445\n",
            "Epoch 72/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.5302 - accuracy: 0.4464\n",
            "Epoch 73/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5281 - accuracy: 0.4488\n",
            "Epoch 74/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.5326 - accuracy: 0.4444\n",
            "Epoch 75/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5319 - accuracy: 0.4442\n",
            "Epoch 76/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.5305 - accuracy: 0.4469\n",
            "Epoch 77/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5286 - accuracy: 0.4488\n",
            "Epoch 78/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.5282 - accuracy: 0.4461\n",
            "Epoch 79/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.5298 - accuracy: 0.4454\n",
            "Epoch 80/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.5283 - accuracy: 0.4458\n",
            "Epoch 81/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5289 - accuracy: 0.4456\n",
            "Epoch 82/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.5296 - accuracy: 0.4465\n",
            "Epoch 83/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5296 - accuracy: 0.4471\n",
            "Epoch 84/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5236 - accuracy: 0.4479\n",
            "Epoch 85/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5260 - accuracy: 0.4479\n",
            "Epoch 86/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.5276 - accuracy: 0.4487\n",
            "Epoch 87/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5265 - accuracy: 0.4465\n",
            "Epoch 88/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.5256 - accuracy: 0.4481\n",
            "Epoch 89/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.5262 - accuracy: 0.4496\n",
            "Epoch 90/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5244 - accuracy: 0.4472\n",
            "Epoch 91/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.5271 - accuracy: 0.4487\n",
            "Epoch 92/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5241 - accuracy: 0.4478\n",
            "Epoch 93/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.5265 - accuracy: 0.4462\n",
            "Epoch 94/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5236 - accuracy: 0.4493\n",
            "Epoch 95/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.5250 - accuracy: 0.4488\n",
            "Epoch 96/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5226 - accuracy: 0.4510\n",
            "Epoch 97/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.5263 - accuracy: 0.4461\n",
            "Epoch 98/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5263 - accuracy: 0.4480\n",
            "Epoch 99/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5226 - accuracy: 0.4489\n",
            "Epoch 100/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.5217 - accuracy: 0.4467\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7bf64c373940>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "primer_modelo.fit(x_train, y_train, epochs=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_jD12IgqEwH"
      },
      "source": [
        "Por ultimo, con un Epoch de 100 se observa un accuracy que converge en 44%,aumentando la precision minimamente comparado al ejemplo anterior, por lo tanto, intentamos con otro modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qq4PuHPRqvbH"
      },
      "source": [
        "#### **Probamos con modelos más complejos**\n",
        "\n",
        "En el siguiente modelo se va a buscar trabajar con las mismas cantidades de layers pero aumentando las neuronas de cada una.\n",
        "\n",
        "Se va a probar ahora con mas neuronas por layers:\n",
        "  - 40 -> 160\n",
        "  - 20 -> 60\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X08a06dZqwSW",
        "outputId": "88d6e80b-dd5c-444a-cce4-1d3e9fc4eef4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.8706 - accuracy: 0.3248\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 1.6950 - accuracy: 0.3930\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 1.6260 - accuracy: 0.4185\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 1.5825 - accuracy: 0.4349\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 1.5454 - accuracy: 0.4442\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 12s 7ms/step - loss: 1.5173 - accuracy: 0.4574\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 12s 7ms/step - loss: 1.4980 - accuracy: 0.4674\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 1.4786 - accuracy: 0.4729\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 1.4552 - accuracy: 0.4816\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.4442 - accuracy: 0.4841\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7bf5b1a3dab0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "segundo_modelo = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(160, activation='relu'),\n",
        "    tf.keras.layers.Dense(60, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "segundo_modelo.compile(optimizer='adam',\n",
        "              loss=SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "segundo_modelo.fit(x_train, y_train, epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGCjODKSxKlA"
      },
      "source": [
        "En este modelo se observa una mejora en la precision, con un accuracy convergando en 48%.\n",
        "Ahora se analizará con un Epoch mayor.\n",
        "\n",
        "Epoch = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jEJxhtfxrPr",
        "outputId": "b8352ed7-f89a-4dfa-f7fe-8fcfbd39c9e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.4292 - accuracy: 0.4893\n",
            "Epoch 2/20\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 1.4132 - accuracy: 0.4939\n",
            "Epoch 3/20\n",
            "1563/1563 [==============================] - 13s 9ms/step - loss: 1.4081 - accuracy: 0.4961\n",
            "Epoch 4/20\n",
            "1563/1563 [==============================] - 12s 7ms/step - loss: 1.3988 - accuracy: 0.4991\n",
            "Epoch 5/20\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.3856 - accuracy: 0.5027\n",
            "Epoch 6/20\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 1.3761 - accuracy: 0.5058\n",
            "Epoch 7/20\n",
            "1563/1563 [==============================] - 12s 7ms/step - loss: 1.3703 - accuracy: 0.5115\n",
            "Epoch 8/20\n",
            "1563/1563 [==============================] - 12s 7ms/step - loss: 1.3636 - accuracy: 0.5101\n",
            "Epoch 9/20\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 1.3551 - accuracy: 0.5134\n",
            "Epoch 10/20\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.3510 - accuracy: 0.5161\n",
            "Epoch 11/20\n",
            "1563/1563 [==============================] - 13s 9ms/step - loss: 1.3383 - accuracy: 0.5210\n",
            "Epoch 12/20\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 1.3371 - accuracy: 0.5230\n",
            "Epoch 13/20\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 1.3322 - accuracy: 0.5235\n",
            "Epoch 14/20\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 1.3215 - accuracy: 0.5269\n",
            "Epoch 15/20\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 1.3156 - accuracy: 0.5310\n",
            "Epoch 16/20\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.3109 - accuracy: 0.5343\n",
            "Epoch 17/20\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 1.3109 - accuracy: 0.5323\n",
            "Epoch 18/20\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 1.3025 - accuracy: 0.5334\n",
            "Epoch 19/20\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 1.2971 - accuracy: 0.5353\n",
            "Epoch 20/20\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.2983 - accuracy: 0.5358\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7bf5b1771b70>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "segundo_modelo.fit(x_train, y_train, epochs=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IQsHoVC1cPx"
      },
      "source": [
        "Despues de aumentar los epochs se observa una mejora en la precision aumentando el accuracy en un 53%.\n",
        "Esto nos da a entender que para mejorar la red neuronal debemos hacer mas grande el modelo, por lo tanto, intentaremos por ultima vez utilizar el segundo modelo con un epochs de 50 y despues crearemos un modelo mas grande."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "segundo_modelo.fit(x_train, y_train, epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mf7LLiudtngh",
        "outputId": "8a024df3-46e6-44ae-d3c3-6b55252b2589"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.2923 - accuracy: 0.5378\n",
            "Epoch 2/50\n",
            "1563/1563 [==============================] - 12s 7ms/step - loss: 1.2843 - accuracy: 0.5400\n",
            "Epoch 3/50\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 1.2841 - accuracy: 0.5394\n",
            "Epoch 4/50\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 1.2796 - accuracy: 0.5431\n",
            "Epoch 5/50\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 1.2731 - accuracy: 0.5453\n",
            "Epoch 6/50\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 1.2695 - accuracy: 0.5444\n",
            "Epoch 7/50\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 1.2652 - accuracy: 0.5477\n",
            "Epoch 8/50\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 1.2596 - accuracy: 0.5503\n",
            "Epoch 9/50\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 1.2579 - accuracy: 0.5497\n",
            "Epoch 10/50\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.2586 - accuracy: 0.5483\n",
            "Epoch 11/50\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 1.2560 - accuracy: 0.5505\n",
            "Epoch 12/50\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 1.2522 - accuracy: 0.5506\n",
            "Epoch 13/50\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 1.2473 - accuracy: 0.5537\n",
            "Epoch 14/50\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 1.2434 - accuracy: 0.5537\n",
            "Epoch 15/50\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.2434 - accuracy: 0.5553\n",
            "Epoch 16/50\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 1.2388 - accuracy: 0.5558\n",
            "Epoch 17/50\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 1.2340 - accuracy: 0.5584\n",
            "Epoch 18/50\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 1.2321 - accuracy: 0.5588\n",
            "Epoch 19/50\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.2294 - accuracy: 0.5590\n",
            "Epoch 20/50\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 1.2302 - accuracy: 0.5590\n",
            "Epoch 21/50\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.2251 - accuracy: 0.5627\n",
            "Epoch 22/50\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.2209 - accuracy: 0.5601\n",
            "Epoch 23/50\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 1.2208 - accuracy: 0.5635\n",
            "Epoch 24/50\n",
            "1563/1563 [==============================] - 15s 9ms/step - loss: 1.2162 - accuracy: 0.5636\n",
            "Epoch 25/50\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 1.2155 - accuracy: 0.5630\n",
            "Epoch 26/50\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.2131 - accuracy: 0.5632\n",
            "Epoch 27/50\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.2125 - accuracy: 0.5636\n",
            "Epoch 28/50\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 1.2071 - accuracy: 0.5674\n",
            "Epoch 29/50\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 1.2034 - accuracy: 0.5680\n",
            "Epoch 30/50\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 1.2067 - accuracy: 0.5666\n",
            "Epoch 31/50\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 1.2002 - accuracy: 0.5700\n",
            "Epoch 32/50\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.2021 - accuracy: 0.5680\n",
            "Epoch 33/50\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 1.1935 - accuracy: 0.5716\n",
            "Epoch 34/50\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.1946 - accuracy: 0.5713\n",
            "Epoch 35/50\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.1899 - accuracy: 0.5734\n",
            "Epoch 36/50\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.1896 - accuracy: 0.5712\n",
            "Epoch 37/50\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 1.1890 - accuracy: 0.5729\n",
            "Epoch 38/50\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 1.1837 - accuracy: 0.5752\n",
            "Epoch 39/50\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.1835 - accuracy: 0.5760\n",
            "Epoch 40/50\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 1.1848 - accuracy: 0.5742\n",
            "Epoch 41/50\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 1.1791 - accuracy: 0.5764\n",
            "Epoch 42/50\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 1.1764 - accuracy: 0.5754\n",
            "Epoch 43/50\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 1.1731 - accuracy: 0.5776\n",
            "Epoch 44/50\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 1.1738 - accuracy: 0.5772\n",
            "Epoch 45/50\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 1.1759 - accuracy: 0.5771\n",
            "Epoch 46/50\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.1706 - accuracy: 0.5781\n",
            "Epoch 47/50\n",
            "1563/1563 [==============================] - 13s 9ms/step - loss: 1.1694 - accuracy: 0.5784\n",
            "Epoch 48/50\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 1.1687 - accuracy: 0.5801\n",
            "Epoch 49/50\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 1.1672 - accuracy: 0.5815\n",
            "Epoch 50/50\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.1630 - accuracy: 0.5817\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7bf5b179a050>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WrtM7-W1mum"
      },
      "source": [
        "Como se observo en el primer modelo, en este caso tambien el aumento de epoch ayudo a que la precision aumente, pasando de un 53% a un 58%, pero sigue siendo bajo.\n",
        "Por ultimo, como se observo en el modelo anterior, si aumentamos las neuronas el modelo mejora, por lo tanto, se diseño un tercer modelo con mas layers, pasaria de 2 con activacion ReLu a 5 con activacion ReLu y dejamos la de softmax.\n",
        "Estas nuevas layers van a tener una cantidad de neuronas similar al ejemplo anterior ya que se observo que ese aumento de neuronas mejoro el modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUPQE_2r1mJH",
        "outputId": "e603e93f-e4e1-4768-bf09-3fc4eab900c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 13s 7ms/step - loss: 1.9242 - accuracy: 0.2951\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 1.7393 - accuracy: 0.3692\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.6642 - accuracy: 0.4002\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 1.6106 - accuracy: 0.4197\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.5744 - accuracy: 0.4314\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 12s 7ms/step - loss: 1.5476 - accuracy: 0.4433\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 12s 7ms/step - loss: 1.5150 - accuracy: 0.4557\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.4970 - accuracy: 0.4624\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 1.4776 - accuracy: 0.4686\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4600 - accuracy: 0.4754\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7bf5b17bd300>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "tercer_modelo = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(164, activation='relu'),\n",
        "    tf.keras.layers.Dense(124, activation='relu'),\n",
        "    tf.keras.layers.Dense(86, activation='relu'),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "tercer_modelo.compile(optimizer='adam',\n",
        "              loss=SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "tercer_modelo.fit(x_train, y_train, epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "428yao6KjfaP"
      },
      "source": [
        "En este tercer modelo se observa que al aumentar las layers la precision no aumentó, al contrario, tuvo un minimo decaimiento por lo tanto, probaré con un epoch mayor y si se comporta igual cambiaré a un nuevo modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pL_bjZPGfYRO",
        "outputId": "93ab3b27-fcc4-4e92-daf6-d6e2b8acd8b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.4343 - accuracy: 0.4853\n",
            "Epoch 2/20\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.4216 - accuracy: 0.4882\n",
            "Epoch 3/20\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.4130 - accuracy: 0.4901\n",
            "Epoch 4/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4014 - accuracy: 0.4967\n",
            "Epoch 5/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.3897 - accuracy: 0.4990\n",
            "Epoch 6/20\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.3801 - accuracy: 0.5064\n",
            "Epoch 7/20\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.3756 - accuracy: 0.5049\n",
            "Epoch 8/20\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.3605 - accuracy: 0.5108\n",
            "Epoch 9/20\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.3519 - accuracy: 0.5149\n",
            "Epoch 10/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.3444 - accuracy: 0.5185\n",
            "Epoch 11/20\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.3336 - accuracy: 0.5181\n",
            "Epoch 12/20\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.3248 - accuracy: 0.5228\n",
            "Epoch 13/20\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.3212 - accuracy: 0.5245\n",
            "Epoch 14/20\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.3146 - accuracy: 0.5267\n",
            "Epoch 15/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3024 - accuracy: 0.5308\n",
            "Epoch 16/20\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.2983 - accuracy: 0.5319\n",
            "Epoch 17/20\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.2887 - accuracy: 0.5353\n",
            "Epoch 18/20\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.2879 - accuracy: 0.5342\n",
            "Epoch 19/20\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.2811 - accuracy: 0.5413\n",
            "Epoch 20/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2738 - accuracy: 0.5432\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7bf5b15c5db0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "tercer_modelo.fit(x_train, y_train, epochs=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "746VFgsLjuCp"
      },
      "source": [
        "Con el epoch de 20 se observa que el accuracy tuvo un aumento minimo, este converge en un 54% cuando en el segundo modelo fue en 53%, por lo tanto, no se justifica el aumento de layers, por ultimo vemos como se comporta con el epoch de 50."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-H7avCGkMDh",
        "outputId": "ab53486a-f55e-4a5b-a0f4-653547817ee0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.2674 - accuracy: 0.5439\n",
            "Epoch 2/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.2618 - accuracy: 0.5459\n",
            "Epoch 3/50\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.2583 - accuracy: 0.5469\n",
            "Epoch 4/50\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 1.2499 - accuracy: 0.5463\n",
            "Epoch 5/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.2432 - accuracy: 0.5518\n",
            "Epoch 6/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.2416 - accuracy: 0.5521\n",
            "Epoch 7/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.2418 - accuracy: 0.5526\n",
            "Epoch 8/50\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 1.2308 - accuracy: 0.5550\n",
            "Epoch 9/50\n",
            "1563/1563 [==============================] - 12s 7ms/step - loss: 1.2264 - accuracy: 0.5596\n",
            "Epoch 10/50\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 1.2197 - accuracy: 0.5608\n",
            "Epoch 11/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.2196 - accuracy: 0.5602\n",
            "Epoch 12/50\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.2111 - accuracy: 0.5626\n",
            "Epoch 13/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.2121 - accuracy: 0.5642\n",
            "Epoch 14/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.2032 - accuracy: 0.5681\n",
            "Epoch 15/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.2011 - accuracy: 0.5659\n",
            "Epoch 16/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.1999 - accuracy: 0.5677\n",
            "Epoch 17/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.1974 - accuracy: 0.5685\n",
            "Epoch 18/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.1901 - accuracy: 0.5717\n",
            "Epoch 19/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.1857 - accuracy: 0.5727\n",
            "Epoch 20/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.1845 - accuracy: 0.5730\n",
            "Epoch 21/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.1778 - accuracy: 0.5752\n",
            "Epoch 22/50\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1751 - accuracy: 0.5754\n",
            "Epoch 23/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.1709 - accuracy: 0.5765\n",
            "Epoch 24/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.1678 - accuracy: 0.5792\n",
            "Epoch 25/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.1683 - accuracy: 0.5801\n",
            "Epoch 26/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.1610 - accuracy: 0.5800\n",
            "Epoch 27/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.1619 - accuracy: 0.5801\n",
            "Epoch 28/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.1613 - accuracy: 0.5818\n",
            "Epoch 29/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.1535 - accuracy: 0.5841\n",
            "Epoch 30/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.1474 - accuracy: 0.5857\n",
            "Epoch 31/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.1508 - accuracy: 0.5831\n",
            "Epoch 32/50\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1481 - accuracy: 0.5849\n",
            "Epoch 33/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.1455 - accuracy: 0.5861\n",
            "Epoch 34/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.1378 - accuracy: 0.5899\n",
            "Epoch 35/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.1405 - accuracy: 0.5912\n",
            "Epoch 36/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.1331 - accuracy: 0.5922\n",
            "Epoch 37/50\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1317 - accuracy: 0.5910\n",
            "Epoch 38/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.1305 - accuracy: 0.5915\n",
            "Epoch 39/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.1283 - accuracy: 0.5933\n",
            "Epoch 40/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.1241 - accuracy: 0.5932\n",
            "Epoch 41/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.1262 - accuracy: 0.5932\n",
            "Epoch 42/50\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1230 - accuracy: 0.5942\n",
            "Epoch 43/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.1214 - accuracy: 0.5956\n",
            "Epoch 44/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.1153 - accuracy: 0.5966\n",
            "Epoch 45/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.1162 - accuracy: 0.5981\n",
            "Epoch 46/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.1124 - accuracy: 0.5964\n",
            "Epoch 47/50\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1031 - accuracy: 0.6005\n",
            "Epoch 48/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.1089 - accuracy: 0.6010\n",
            "Epoch 49/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.1044 - accuracy: 0.6017\n",
            "Epoch 50/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.0989 - accuracy: 0.6018\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7bf5b161db40>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "tercer_modelo.fit(x_train, y_train, epochs=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdWi1etOybR5"
      },
      "source": [
        "Como se observó utilizando 20 epochs no se justifica el aumento de layers ya que con 50 epoch pasa de un 58% a un 60% de precisión."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOmHzDFk70FJ"
      },
      "source": [
        "Por ultimo, voy a probar un modelo con mas neuronas que el tercero para ver si mejora considerablemente su precision y si justifica los costos computacionales que este conlleva."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okOncdEC8Nxf"
      },
      "outputs": [],
      "source": [
        "cuarto_modelo = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(1024, activation='relu'),\n",
        "    tf.keras.layers.Dense(896, activation='relu'),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "cuarto_modelo.compile(optimizer='adam',\n",
        "              loss=SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "cuarto_modelo.fit(x_train, y_train, epochs=10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con un epochs de 10 se observa un minimo aumento injustificable en el accuracy como para aplicar estos cambios pero, continuamos viendo como se comporta con mas epochs.\n",
        "epochs = 20."
      ],
      "metadata": {
        "id": "ohBvvU9XIFbd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zipC_GgpLQKF",
        "outputId": "2c11ef7f-113e-4ac4-bb8a-b5041fbaf9c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1563/1563 [==============================] - 94s 60ms/step - loss: 1.3717 - accuracy: 0.5081\n",
            "Epoch 2/20\n",
            "1563/1563 [==============================] - 97s 62ms/step - loss: 1.3446 - accuracy: 0.5200\n",
            "Epoch 3/20\n",
            "1563/1563 [==============================] - 96s 62ms/step - loss: 1.3210 - accuracy: 0.5262\n",
            "Epoch 4/20\n",
            "1563/1563 [==============================] - 95s 61ms/step - loss: 1.3007 - accuracy: 0.5333\n",
            "Epoch 5/20\n",
            "1563/1563 [==============================] - 96s 61ms/step - loss: 1.2794 - accuracy: 0.5414\n",
            "Epoch 6/20\n",
            "1563/1563 [==============================] - 95s 61ms/step - loss: 1.2555 - accuracy: 0.5469\n",
            "Epoch 7/20\n",
            "1563/1563 [==============================] - 96s 61ms/step - loss: 1.2261 - accuracy: 0.5584\n",
            "Epoch 8/20\n",
            "1563/1563 [==============================] - 94s 60ms/step - loss: 1.2107 - accuracy: 0.5630\n",
            "Epoch 9/20\n",
            "1563/1563 [==============================] - 96s 61ms/step - loss: 1.1849 - accuracy: 0.5712\n",
            "Epoch 10/20\n",
            "1563/1563 [==============================] - 95s 61ms/step - loss: 1.1591 - accuracy: 0.5799\n",
            "Epoch 11/20\n",
            "1563/1563 [==============================] - 95s 61ms/step - loss: 1.1289 - accuracy: 0.5899\n",
            "Epoch 12/20\n",
            "1563/1563 [==============================] - 95s 61ms/step - loss: 1.1079 - accuracy: 0.5967\n",
            "Epoch 13/20\n",
            "1563/1563 [==============================] - 97s 62ms/step - loss: 1.0872 - accuracy: 0.6078\n",
            "Epoch 14/20\n",
            "1563/1563 [==============================] - 95s 61ms/step - loss: 1.0663 - accuracy: 0.6132\n",
            "Epoch 15/20\n",
            "1563/1563 [==============================] - 96s 62ms/step - loss: 1.0414 - accuracy: 0.6222\n",
            "Epoch 16/20\n",
            "1563/1563 [==============================] - 97s 62ms/step - loss: 1.0163 - accuracy: 0.6291\n",
            "Epoch 17/20\n",
            "1563/1563 [==============================] - 96s 62ms/step - loss: 0.9963 - accuracy: 0.6370\n",
            "Epoch 18/20\n",
            "1563/1563 [==============================] - 98s 63ms/step - loss: 0.9689 - accuracy: 0.6478\n",
            "Epoch 19/20\n",
            "1563/1563 [==============================] - 96s 62ms/step - loss: 0.9514 - accuracy: 0.6523\n",
            "Epoch 20/20\n",
            "1563/1563 [==============================] - 98s 63ms/step - loss: 0.9447 - accuracy: 0.6551\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7bf5ab4f30d0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "cuarto_modelo.fit(x_train, y_train, epochs=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui se observa un aumento considerable para realizar estos cambios de arquitectura, por lo tanto, parece que el cambio necesario era el aumento de neuronas.\n",
        "Por ultimo, probamos con epochs de 50."
      ],
      "metadata": {
        "id": "y0clx9pDIWfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cuarto_modelo.fit(x_train, y_train, epochs=50)"
      ],
      "metadata": {
        "id": "3mO7skhp5foT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con 50 epochs se interpreta que al realizar mas ingresos a la red neuronal la precisión aumenta, como en este ejemplo que pasamos a un 86% de precisión, siendo la precisión mas alta conseguida hasta el momento.\n",
        "Por ultimo, voy a probar con un modelo con menos layers y otro con un aumento de layers considerable pero con pocas neuronas, para asi, concluir con lo dicho anteriormente."
      ],
      "metadata": {
        "id": "hYbz3Q9KIok1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "quinto_modelo = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(1024, activation='relu'),\n",
        "    tf.keras.layers.Dense(896, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "quinto_modelo.compile(optimizer='adam',\n",
        "              loss=SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "quinto_modelo.fit(x_train, y_train, epochs=50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMbPnoKHPPoT",
        "outputId": "7f25f1f5-a974-410c-e8aa-c3f32a423124"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1563/1563 [==============================] - 48s 30ms/step - loss: 1.8662 - accuracy: 0.3284\n",
            "Epoch 2/50\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.6682 - accuracy: 0.4003\n",
            "Epoch 3/50\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.5932 - accuracy: 0.4267\n",
            "Epoch 4/50\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.5400 - accuracy: 0.4498\n",
            "Epoch 5/50\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.5078 - accuracy: 0.4562\n",
            "Epoch 6/50\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.4804 - accuracy: 0.4695\n",
            "Epoch 7/50\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.4567 - accuracy: 0.4785\n",
            "Epoch 8/50\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.4367 - accuracy: 0.4845\n",
            "Epoch 9/50\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.4164 - accuracy: 0.4921\n",
            "Epoch 10/50\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.3996 - accuracy: 0.4983\n",
            "Epoch 11/50\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.3893 - accuracy: 0.5007\n",
            "Epoch 12/50\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.3729 - accuracy: 0.5061\n",
            "Epoch 13/50\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.3609 - accuracy: 0.5099\n",
            "Epoch 14/50\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.3434 - accuracy: 0.5173\n",
            "Epoch 15/50\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.3336 - accuracy: 0.5215\n",
            "Epoch 16/50\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.3245 - accuracy: 0.5234\n",
            "Epoch 17/50\n",
            "1563/1563 [==============================] - 48s 31ms/step - loss: 1.3076 - accuracy: 0.5334\n",
            "Epoch 18/50\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.3013 - accuracy: 0.5335\n",
            "Epoch 19/50\n",
            "1563/1563 [==============================] - 48s 31ms/step - loss: 1.2931 - accuracy: 0.5381\n",
            "Epoch 20/50\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.2781 - accuracy: 0.5404\n",
            "Epoch 21/50\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.2710 - accuracy: 0.5441\n",
            "Epoch 22/50\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.2618 - accuracy: 0.5473\n",
            "Epoch 23/50\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.2490 - accuracy: 0.5523\n",
            "Epoch 24/50\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.2412 - accuracy: 0.5538\n",
            "Epoch 25/50\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.2319 - accuracy: 0.5581\n",
            "Epoch 26/50\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.2232 - accuracy: 0.5598\n",
            "Epoch 27/50\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.2160 - accuracy: 0.5647\n",
            "Epoch 28/50\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.2135 - accuracy: 0.5626\n",
            "Epoch 29/50\n",
            "1563/1563 [==============================] - 48s 31ms/step - loss: 1.2011 - accuracy: 0.5670\n",
            "Epoch 30/50\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.1947 - accuracy: 0.5716\n",
            "Epoch 31/50\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.1896 - accuracy: 0.5733\n",
            "Epoch 32/50\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.1812 - accuracy: 0.5733\n",
            "Epoch 33/50\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.1749 - accuracy: 0.5784\n",
            "Epoch 34/50\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.1703 - accuracy: 0.5780\n",
            "Epoch 35/50\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.1594 - accuracy: 0.5828\n",
            "Epoch 36/50\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.1592 - accuracy: 0.5817\n",
            "Epoch 37/50\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.1501 - accuracy: 0.5882\n",
            "Epoch 38/50\n",
            "1563/1563 [==============================] - 48s 30ms/step - loss: 1.1398 - accuracy: 0.5900\n",
            "Epoch 39/50\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.1379 - accuracy: 0.5922\n",
            "Epoch 40/50\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.1300 - accuracy: 0.5919\n",
            "Epoch 41/50\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.1286 - accuracy: 0.5955\n",
            "Epoch 42/50\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.1240 - accuracy: 0.5946\n",
            "Epoch 43/50\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.1134 - accuracy: 0.5971\n",
            "Epoch 44/50\n",
            "1563/1563 [==============================] - 48s 31ms/step - loss: 1.1139 - accuracy: 0.5995\n",
            "Epoch 45/50\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.1012 - accuracy: 0.6023\n",
            "Epoch 46/50\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.0938 - accuracy: 0.6060\n",
            "Epoch 47/50\n",
            "1563/1563 [==============================] - 48s 31ms/step - loss: 1.0932 - accuracy: 0.6057\n",
            "Epoch 48/50\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 1.0901 - accuracy: 0.6082\n",
            "Epoch 49/50\n",
            "1563/1563 [==============================] - 48s 31ms/step - loss: 1.0857 - accuracy: 0.6099\n",
            "Epoch 50/50\n",
            "1563/1563 [==============================] - 48s 31ms/step - loss: 1.0784 - accuracy: 0.6129\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ada2b4e3fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui se observa que al disminuir las layers el modelo disminuye su eficiencia un 20%."
      ],
      "metadata": {
        "id": "m1_IDPC-dvMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sexto_modelo = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(164, activation='relu'),\n",
        "    tf.keras.layers.Dense(124, activation='relu'),\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "    tf.keras.layers.Dense(80, activation='relu'),\n",
        "    tf.keras.layers.Dense(70, activation='relu'),\n",
        "    tf.keras.layers.Dense(60, activation='relu'),\n",
        "    tf.keras.layers.Dense(43, activation='relu'),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(24, activation='relu'),\n",
        "    tf.keras.layers.Dense(12, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "sexto_modelo.compile(optimizer='adam',\n",
        "              loss=SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "sexto_modelo.fit(x_train, y_train, epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXYbVcAwUHZi",
        "outputId": "bd82923f-f53c-48d0-c9d2-0c1cfb60d93c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1563/1563 [==============================] - 12s 6ms/step - loss: 2.0353 - accuracy: 0.2261\n",
            "Epoch 2/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.8369 - accuracy: 0.3211\n",
            "Epoch 3/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.7685 - accuracy: 0.3529\n",
            "Epoch 4/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.7125 - accuracy: 0.3761\n",
            "Epoch 5/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.6624 - accuracy: 0.3989\n",
            "Epoch 6/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.6306 - accuracy: 0.4105\n",
            "Epoch 7/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.5955 - accuracy: 0.4245\n",
            "Epoch 8/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.5751 - accuracy: 0.4345\n",
            "Epoch 9/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.5582 - accuracy: 0.4384\n",
            "Epoch 10/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.5381 - accuracy: 0.4492\n",
            "Epoch 11/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.5235 - accuracy: 0.4522\n",
            "Epoch 12/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.5114 - accuracy: 0.4558\n",
            "Epoch 13/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.5031 - accuracy: 0.4622\n",
            "Epoch 14/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.4887 - accuracy: 0.4653\n",
            "Epoch 15/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.4771 - accuracy: 0.4668\n",
            "Epoch 16/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.4652 - accuracy: 0.4736\n",
            "Epoch 17/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4596 - accuracy: 0.4755\n",
            "Epoch 18/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.4444 - accuracy: 0.4810\n",
            "Epoch 19/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.4380 - accuracy: 0.4841\n",
            "Epoch 20/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.4218 - accuracy: 0.4866\n",
            "Epoch 21/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.4200 - accuracy: 0.4913\n",
            "Epoch 22/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.4103 - accuracy: 0.4918\n",
            "Epoch 23/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.4023 - accuracy: 0.4977\n",
            "Epoch 24/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.3951 - accuracy: 0.4968\n",
            "Epoch 25/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.3879 - accuracy: 0.5002\n",
            "Epoch 26/50\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.3792 - accuracy: 0.5031\n",
            "Epoch 27/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.3720 - accuracy: 0.5056\n",
            "Epoch 28/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.3694 - accuracy: 0.5087\n",
            "Epoch 29/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.3625 - accuracy: 0.5090\n",
            "Epoch 30/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.3563 - accuracy: 0.5133\n",
            "Epoch 31/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.3474 - accuracy: 0.5165\n",
            "Epoch 32/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.3434 - accuracy: 0.5170\n",
            "Epoch 33/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.3369 - accuracy: 0.5161\n",
            "Epoch 34/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.3315 - accuracy: 0.5203\n",
            "Epoch 35/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.3298 - accuracy: 0.5189\n",
            "Epoch 36/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.3226 - accuracy: 0.5233\n",
            "Epoch 37/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.3151 - accuracy: 0.5251\n",
            "Epoch 38/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.3126 - accuracy: 0.5274\n",
            "Epoch 39/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.3000 - accuracy: 0.5308\n",
            "Epoch 40/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.3032 - accuracy: 0.5309\n",
            "Epoch 41/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.2936 - accuracy: 0.5347\n",
            "Epoch 42/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.2910 - accuracy: 0.5334\n",
            "Epoch 43/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.2855 - accuracy: 0.5375\n",
            "Epoch 44/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.2778 - accuracy: 0.5400\n",
            "Epoch 45/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.2778 - accuracy: 0.5384\n",
            "Epoch 46/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.2735 - accuracy: 0.5410\n",
            "Epoch 47/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.2693 - accuracy: 0.5445\n",
            "Epoch 48/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.2648 - accuracy: 0.5432\n",
            "Epoch 49/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.2558 - accuracy: 0.5461\n",
            "Epoch 50/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.2560 - accuracy: 0.5479\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ada2b294310>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como habiamos analizado anteriormente, el mejor modelo obtenido fue el que  mayor numero de neuronal contenia. El tener gran cantidad de layers no genero un aumento de la precision considerable como para generar ese gasto computacional, por lo tanto, el modelo mas optimo para este dataset seria el siguiente:\n",
        "\n",
        "    cuarto_modelo = tf.keras.models.Sequential([\n",
        "\n",
        "          tf.keras.layers.Flatten(),\n",
        "          tf.keras.layers.Dense(1024, activation='relu'),\n",
        "          tf.keras.layers.Dense(896, activation='relu'),\n",
        "          tf.keras.layers.Dense(512, activation='relu'),\n",
        "          tf.keras.layers.Dense(256, activation='relu'),\n",
        "          tf.keras.layers.Dense(128, activation='relu'),\n",
        "          tf.keras.layers.Dense(10, activation='softmax')\n",
        "          ])"
      ],
      "metadata": {
        "id": "JoIY0lhGJoex"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHRVqrAVqrVy"
      },
      "source": [
        "# 2) Implementacion de CNN\n",
        "Primero vemos las dimensiones de las imagenes\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdeMsuRarXG2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42c7d1a3-cc03-4b5f-ed83-476a00de2404"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "x_train[0].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDKG7wlps-Fh"
      },
      "source": [
        "Continuamos cambiandoles el tamaño con la funcion reshape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNiRGAtBtaCM"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.reshape(50000, 32, 32, 3)\n",
        "x_test = x_test.reshape(10000, 32, 32, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPW7C_wDuEJa"
      },
      "source": [
        "Ya modificados los tamaños de las imagenes realizamos la extracion de los feature.\n",
        "Esto va a realizarse utilizando, para cada imagen leida, 3 layers, cada una compuesta por una red Convolucional con una funcion de activacion ReLu para filtrar la imagen para un feature particular y detectar ese feature dentro de la imagen filtrada, y una Max Pooling para reducir el tamaño y compactar la informacion recibida en la entrada.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1A9lb0jty1Gu"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "#Creamos el modelo\n",
        "modelo_1 = Sequential();\n",
        "\n",
        "#Agregamos las layers\n",
        "\n",
        "modelo_1.add(Conv2D(128, kernel_size=3, activation='relu', input_shape=(32, 32, 3)))\n",
        "modelo_1.add(MaxPooling2D(pool_size=2))\n",
        "modelo_1.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
        "modelo_1.add(MaxPooling2D(pool_size=2))\n",
        "modelo_1.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
        "modelo_1.add(MaxPooling2D(pool_size=2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTTK293vxP0d"
      },
      "source": [
        "Tambien utilizaremos las layers que obtuvimos en el inciso 1, ya que son capaces de detectar otro tipo de feature y de realizar la clasificacion."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelo_1.add(Flatten())\n",
        "modelo_1.add(Dense(1024, activation='relu')),\n",
        "modelo_1.add(Dense(896, activation='relu')),\n",
        "modelo_1.add(Dense(512, activation='relu')),\n",
        "modelo_1.add(Dense(256, activation='relu')),\n",
        "modelo_1.add(Dense(128, activation='relu')),\n",
        "modelo_1.add(Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "wWBQZLdurqd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora seguimos el procedimiento que hicimos anteriormente, compilamos y entrenamos."
      ],
      "metadata": {
        "id": "tEYt9-8QsDEX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo_1.compile(optimizer='adam',\n",
        "              loss=SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "modelo_1.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3mC4Sr4sLDK",
        "outputId": "dc55fe5f-1175-4c30-eeb8-f031dbbde62b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 240s 153ms/step - loss: 1.2090 - accuracy: 0.5691 - val_loss: 1.1951 - val_accuracy: 0.5742\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 230s 147ms/step - loss: 1.1166 - accuracy: 0.6045 - val_loss: 1.1178 - val_accuracy: 0.6042\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 229s 147ms/step - loss: 1.0379 - accuracy: 0.6337 - val_loss: 1.1301 - val_accuracy: 0.6202\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7eecfb601ab0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este primero modelo de observa un accuracy que ronda entre 56% y 63%, probaremos con 5 epochs para ver si aumenta."
      ],
      "metadata": {
        "id": "kA1a4OcoWaJL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo_1.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnvasVDa_HF8",
        "outputId": "4fcebd1d-895b-41a7-e1bc-8919aac8abed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 228s 145ms/step - loss: 0.5809 - accuracy: 0.7946 - val_loss: 1.0613 - val_accuracy: 0.6743\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 227s 145ms/step - loss: 0.5317 - accuracy: 0.8120 - val_loss: 1.0915 - val_accuracy: 0.6604\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 225s 144ms/step - loss: 0.4961 - accuracy: 0.8233 - val_loss: 1.2078 - val_accuracy: 0.6624\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 227s 145ms/step - loss: 0.4522 - accuracy: 0.8410 - val_loss: 1.1090 - val_accuracy: 0.6773\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 228s 146ms/step - loss: 0.4092 - accuracy: 0.8548 - val_loss: 1.2843 - val_accuracy: 0.6608\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7eecf8be9720>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con 5 epochs se observa que el accuracy converge en 85%, por lo tanto, se puede deducir que al tener tantas neuronas y filtros 3 epochs eran pocos ingresos a la red como para poder calcular bien su accuracy, ahora probaremos con 10."
      ],
      "metadata": {
        "id": "HSuKPOZ6WsIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo_1.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWohWZeJ_Hgh",
        "outputId": "08808a9d-9fe1-41cf-9bcf-f3e90bd9576d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 229s 146ms/step - loss: 0.3842 - accuracy: 0.8672 - val_loss: 1.3004 - val_accuracy: 0.6745\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 226s 145ms/step - loss: 0.3459 - accuracy: 0.8799 - val_loss: 1.4439 - val_accuracy: 0.6623\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 238s 152ms/step - loss: 0.3377 - accuracy: 0.8821 - val_loss: 1.4004 - val_accuracy: 0.6617\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 227s 145ms/step - loss: 0.3075 - accuracy: 0.8924 - val_loss: 1.3642 - val_accuracy: 0.6715\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 227s 145ms/step - loss: 0.2795 - accuracy: 0.9032 - val_loss: 1.4080 - val_accuracy: 0.6653\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 225s 144ms/step - loss: 0.2743 - accuracy: 0.9047 - val_loss: 1.4729 - val_accuracy: 0.6615\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 226s 145ms/step - loss: 0.2470 - accuracy: 0.9164 - val_loss: 1.5288 - val_accuracy: 0.6593\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 225s 144ms/step - loss: 0.2342 - accuracy: 0.9202 - val_loss: 1.6037 - val_accuracy: 0.6688\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 226s 145ms/step - loss: 0.2294 - accuracy: 0.9224 - val_loss: 1.6121 - val_accuracy: 0.6640\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 225s 144ms/step - loss: 0.2079 - accuracy: 0.9283 - val_loss: 1.8317 - val_accuracy: 0.6528\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7eecf8e71570>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como comente anteriormente, con 10 epochs se concluye que a mas neuronas y filtros es necesario mas epochs para poder analizar la eficiencia del modelo planteado correctamente."
      ],
      "metadata": {
        "id": "LQ9RBqbwXDY4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Segundo modelo CNN\n"
      ],
      "metadata": {
        "id": "MholP0DVvzbQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este segundo modelo lo que se busco es mantener las layers del ejercicios 1 ya que fueron las mas optimas y le modificamos a las capas convolucionales la cantidad de filtros aplicados."
      ],
      "metadata": {
        "id": "2MCukbFg0qtu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "#Creamos el modelo\n",
        "modelo_2 = Sequential();\n",
        "\n",
        "#Agregamos las layers\n",
        "\n",
        "modelo_2.add(Conv2D(460, kernel_size=3, activation='relu', input_shape=(32, 32, 3)))\n",
        "modelo_2.add(MaxPooling2D(pool_size=2))\n",
        "modelo_2.add(Conv2D(264, kernel_size=3, activation='relu', input_shape=(32, 32, 3)))\n",
        "modelo_2.add(MaxPooling2D(pool_size=2))\n",
        "modelo_2.add(Conv2D(132, kernel_size=3, activation='relu', input_shape=(32, 32, 3)))\n",
        "modelo_2.add(MaxPooling2D(pool_size=2))\n",
        "modelo_2.add(Flatten())\n",
        "modelo_2.add(Dense(1024, activation='relu')),\n",
        "modelo_2.add(Dense(896, activation='relu')),\n",
        "modelo_2.add(Dense(512, activation='relu')),\n",
        "modelo_2.add(Dense(256, activation='relu')),\n",
        "modelo_2.add(Dense(128, activation='relu')),\n",
        "modelo_2.add(Dense(10, activation='softmax'))\n",
        "\n",
        "modelo_2.compile(optimizer='adam',\n",
        "              loss=SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "modelo_2.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=3)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3krvTavgwBkC",
        "outputId": "935b4b24-9198-4772-8234-e4251b39683d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 1074s 686ms/step - loss: 1.7128 - accuracy: 0.3474 - val_loss: 1.4222 - val_accuracy: 0.4786\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 1069s 684ms/step - loss: 1.2843 - accuracy: 0.5387 - val_loss: 1.1855 - val_accuracy: 0.5770\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 1071s 685ms/step - loss: 1.1025 - accuracy: 0.6125 - val_loss: 1.1248 - val_accuracy: 0.6122\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x791320a1e4a0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En comparación al ejemplo anterior, este comdelo con 3 epochs varia mucho su accuracy, por lo tanto, probamos con 5 y 10"
      ],
      "metadata": {
        "id": "j0gdz6I_Xo49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo_2.compile(optimizer='adam',\n",
        "              loss=SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "modelo_2.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pgb8ASPPnHV",
        "outputId": "38292033-8bea-4f80-c2fb-7a6cc1133906"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 1522s 973ms/step - loss: 0.9713 - accuracy: 0.6617 - val_loss: 1.0665 - val_accuracy: 0.6355\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 1489s 953ms/step - loss: 0.8743 - accuracy: 0.6959 - val_loss: 1.0442 - val_accuracy: 0.6325\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 1490s 953ms/step - loss: 0.7937 - accuracy: 0.7252 - val_loss: 0.9519 - val_accuracy: 0.6816\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 1483s 949ms/step - loss: 0.7271 - accuracy: 0.7468 - val_loss: 0.9722 - val_accuracy: 0.6747\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 1486s 951ms/step - loss: 0.6698 - accuracy: 0.7667 - val_loss: 0.9068 - val_accuracy: 0.6985\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7eec8e59b1f0>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con 5 epochs se nota valores mas cercanos pero menores al ejemplo anterior."
      ],
      "metadata": {
        "id": "8vXK4Jf1mwSm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo_2.compile(optimizer='adam',\n",
        "              loss=SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "modelo_2.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCOUBruXyHTd",
        "outputId": "bcd0823a-d543-4f78-e4ca-05d721710b08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 1083s 692ms/step - loss: 0.9905 - accuracy: 0.6537 - val_loss: 1.0474 - val_accuracy: 0.6486\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 1073s 687ms/step - loss: 0.9082 - accuracy: 0.6857 - val_loss: 0.9788 - val_accuracy: 0.6616\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 1068s 684ms/step - loss: 0.8382 - accuracy: 0.7085 - val_loss: 0.9784 - val_accuracy: 0.6757\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 1066s 682ms/step - loss: 0.7765 - accuracy: 0.7311 - val_loss: 0.9250 - val_accuracy: 0.6900\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 1069s 684ms/step - loss: 0.7239 - accuracy: 0.7491 - val_loss: 0.9703 - val_accuracy: 0.6746\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 1096s 701ms/step - loss: 0.6744 - accuracy: 0.7653 - val_loss: 1.0110 - val_accuracy: 0.6805\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 1071s 686ms/step - loss: 0.6206 - accuracy: 0.7838 - val_loss: 0.9287 - val_accuracy: 0.6988\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 1076s 688ms/step - loss: 0.5769 - accuracy: 0.8014 - val_loss: 0.9558 - val_accuracy: 0.6925\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 1072s 686ms/step - loss: 0.5335 - accuracy: 0.8152 - val_loss: 0.9732 - val_accuracy: 0.7034\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 1069s 684ms/step - loss: 0.4866 - accuracy: 0.8309 - val_loss: 1.0876 - val_accuracy: 0.6988\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x791320881f30>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui se observa que el 2do modelo tiene un  accuracy del 83%, siendo menor que el 92% del primer modelo CNN.\n",
        "Ahora, haremos un 3er modelo para seguir analizando diferentes arquitecturas."
      ],
      "metadata": {
        "id": "aUcQYMqsm5-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "#Creamos el modelo\n",
        "modelo_3 = Sequential();\n",
        "\n",
        "#Agregamos las layers\n",
        "\n",
        "modelo_3.add(Conv2D(24, kernel_size=3, activation='relu', input_shape=(32, 32, 3)))\n",
        "modelo_3.add(MaxPooling2D(pool_size=2))\n",
        "modelo_3.add(Conv2D(20, kernel_size=3, activation='relu'))\n",
        "modelo_3.add(MaxPooling2D(pool_size=2))\n",
        "modelo_3.add(Conv2D(18, kernel_size=3, activation='relu'))\n",
        "modelo_3.add(MaxPooling2D(pool_size=2))\n",
        "modelo_3.add(Flatten())\n",
        "modelo_3.add(Dense(1024, activation='relu')),\n",
        "modelo_3.add(Dense(896, activation='relu')),\n",
        "modelo_3.add(Dense(512, activation='relu')),\n",
        "modelo_3.add(Dense(256, activation='relu')),\n",
        "modelo_3.add(Dense(128, activation='relu')),\n",
        "modelo_3.add(Dense(10, activation='softmax'))\n"
      ],
      "metadata": {
        "id": "5JI8vd18UQAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelo_3.compile(optimizer='adam',\n",
        "              loss=SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "modelo_3.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=3)\n",
        "\n",
        "modelo_3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCh7jhb_yJEG",
        "outputId": "c5d2b438-8b43-4fc2-a0af-e48dd9cacdbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 97s 61ms/step - loss: 1.8271 - accuracy: 0.2834 - val_loss: 1.6336 - val_accuracy: 0.3894\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 90s 58ms/step - loss: 1.5578 - accuracy: 0.4168 - val_loss: 1.4846 - val_accuracy: 0.4462\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 91s 59ms/step - loss: 1.4232 - accuracy: 0.4780 - val_loss: 1.3821 - val_accuracy: 0.4980\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_35 (Conv2D)          (None, 30, 30, 24)        672       \n",
            "                                                                 \n",
            " max_pooling2d_30 (MaxPoolin  (None, 15, 15, 24)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_36 (Conv2D)          (None, 13, 13, 12)        2604      \n",
            "                                                                 \n",
            " max_pooling2d_31 (MaxPoolin  (None, 6, 6, 12)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_37 (Conv2D)          (None, 4, 4, 8)           872       \n",
            "                                                                 \n",
            " max_pooling2d_32 (MaxPoolin  (None, 2, 2, 8)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 1024)              33792     \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 896)               918400    \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 512)               459264    \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,581,118\n",
            "Trainable params: 1,581,118\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelo_3.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=5)"
      ],
      "metadata": {
        "id": "NDYEVdYayLYk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "476a5250-ddb9-4cb3-a7bc-8e60cc3a4da9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 1.6197 - accuracy: 0.3930 - val_loss: 1.4840 - val_accuracy: 0.4466\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 48s 31ms/step - loss: 1.4585 - accuracy: 0.4643 - val_loss: 1.4541 - val_accuracy: 0.4742\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 48s 31ms/step - loss: 1.3648 - accuracy: 0.5047 - val_loss: 1.3641 - val_accuracy: 0.5001\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 46s 29ms/step - loss: 1.3078 - accuracy: 0.5286 - val_loss: 1.3086 - val_accuracy: 0.5353\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 46s 29ms/step - loss: 1.2587 - accuracy: 0.5478 - val_loss: 1.2830 - val_accuracy: 0.5420\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 30, 30, 24)        672       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 15, 15, 24)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 13, 13, 12)        2604      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 6, 6, 12)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 4, 4, 8)           872       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 2, 2, 8)          0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 32)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              33792     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 896)               918400    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 512)               459264    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,581,118\n",
            "Trainable params: 1,581,118\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelo_3.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10)"
      ],
      "metadata": {
        "id": "5PROheQ3yNMX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38b5f3a4-dd84-4cb3-9f2a-2d5c36bf965c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 47s 29ms/step - loss: 1.2105 - accuracy: 0.5690 - val_loss: 1.2140 - val_accuracy: 0.5639\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 46s 29ms/step - loss: 1.1706 - accuracy: 0.5806 - val_loss: 1.2280 - val_accuracy: 0.5652\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 46s 29ms/step - loss: 1.1424 - accuracy: 0.5913 - val_loss: 1.2046 - val_accuracy: 0.5754\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 46s 29ms/step - loss: 1.1086 - accuracy: 0.6034 - val_loss: 1.1633 - val_accuracy: 0.5861\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 48s 31ms/step - loss: 1.0784 - accuracy: 0.6165 - val_loss: 1.1731 - val_accuracy: 0.5849\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.0489 - accuracy: 0.6278 - val_loss: 1.1498 - val_accuracy: 0.5912\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.0204 - accuracy: 0.6345 - val_loss: 1.1496 - val_accuracy: 0.5924\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 46s 30ms/step - loss: 0.9979 - accuracy: 0.6455 - val_loss: 1.1523 - val_accuracy: 0.6052\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 0.9655 - accuracy: 0.6546 - val_loss: 1.1515 - val_accuracy: 0.6052\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 0.9353 - accuracy: 0.6635 - val_loss: 1.2260 - val_accuracy: 0.5854\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 30, 30, 24)        672       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 15, 15, 24)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 13, 13, 12)        2604      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 6, 6, 12)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 4, 4, 8)           872       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 2, 2, 8)          0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 32)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              33792     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 896)               918400    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 512)               459264    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,581,118\n",
            "Trainable params: 1,581,118\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nuevamente no se observa un aumento del accuracy al primer modelo, por lo tanto concluimos que el modelo 1 es posiblemente una buena arquitectura para este tipo de dataset."
      ],
      "metadata": {
        "id": "deHu8Mv0_lbu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# COMPARAR RENDIMIENTO CON OTRO DATASET\n",
        "A continuacion, probaré el rendmiento de la mejor arquitectura obtenida anteriormente en otro dataset para analizar su rendimiento en otros ejemplos."
      ],
      "metadata": {
        "id": "qSq4Mx8YAnA9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.losses import SparseCategoricalCrossentropy\n",
        "from keras.datasets import fashion_mnist\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "plt.imshow(x_train[0])\n",
        "print('Cifar10 Dataset Shape:')\n",
        "print('X_train: ' + str(x_train.shape))\n",
        "print('Y_train: ' + str(y_train.shape))\n",
        "print('X_test:  '  + str(x_test.shape))\n",
        "print('Y_test:  '  + str(y_test.shape))\n",
        "x_train[0].shape\n",
        "x_train = x_train.reshape(60000, 28, 28,1)\n",
        "x_test = x_test.reshape(10000, 28, 28,1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "B5Ke-N7YD-xH",
        "outputId": "cc1495f3-c72e-4a51-90d0-c52116cdd1c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cifar10 Dataset Shape:\n",
            "X_train: (60000, 28, 28)\n",
            "Y_train: (60000,)\n",
            "X_test:  (10000, 28, 28)\n",
            "Y_test:  (10000,)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "#Creamos el modelo\n",
        "modelo_N = Sequential()\n",
        "\n",
        "#Agregamos las layers\n",
        "\n",
        "modelo_N.add(Conv2D(128, kernel_size=3, activation='relu', input_shape=(28,28,1)))\n",
        "modelo_N.add(MaxPooling2D(pool_size=2))\n",
        "modelo_N.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
        "modelo_N.add(MaxPooling2D(pool_size=2))\n",
        "modelo_N.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
        "modelo_N.add(MaxPooling2D(pool_size=2))\n",
        "modelo_N.add(Flatten())\n",
        "modelo_N.add(Dense(1024, activation='relu')),\n",
        "modelo_N.add(Dense(896, activation='relu')),\n",
        "modelo_N.add(Dense(512, activation='relu')),\n",
        "modelo_N.add(Dense(256, activation='relu')),\n",
        "modelo_N.add(Dense(128, activation='relu')),\n",
        "modelo_N.add(Dense(10, activation='softmax'))\n",
        "\n",
        "modelo_N.compile(optimizer='adam',\n",
        "              loss=SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "modelo_N.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qm66wD9CB-aO",
        "outputId": "c9fcb8e2-2309-4be3-b49d-09a38796e101"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 141s 75ms/step - loss: 0.6318 - accuracy: 0.7707 - val_loss: 0.5324 - val_accuracy: 0.8084\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 139s 74ms/step - loss: 0.4693 - accuracy: 0.8311 - val_loss: 0.4671 - val_accuracy: 0.8300\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 137s 73ms/step - loss: 0.4185 - accuracy: 0.8496 - val_loss: 0.4071 - val_accuracy: 0.8545\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 137s 73ms/step - loss: 0.3848 - accuracy: 0.8604 - val_loss: 0.4390 - val_accuracy: 0.8484\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 138s 73ms/step - loss: 0.3642 - accuracy: 0.8680 - val_loss: 0.3941 - val_accuracy: 0.8575\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 137s 73ms/step - loss: 0.3414 - accuracy: 0.8752 - val_loss: 0.4059 - val_accuracy: 0.8603\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 139s 74ms/step - loss: 0.3301 - accuracy: 0.8808 - val_loss: 0.3702 - val_accuracy: 0.8694\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 136s 72ms/step - loss: 0.3162 - accuracy: 0.8858 - val_loss: 0.4336 - val_accuracy: 0.8589\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 138s 74ms/step - loss: 0.3036 - accuracy: 0.8908 - val_loss: 0.3692 - val_accuracy: 0.8746\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 135s 72ms/step - loss: 0.2911 - accuracy: 0.8939 - val_loss: 0.3865 - val_accuracy: 0.8802\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7c1a346db670>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CONCLUSIÓN\n",
        "Observando los resultados obtenidos se puede concluir que, al realizar las arquitecturas de las redes neuronales los mejores resultados fueron obtenidos en funcion al aumento de neuronal y no tanto al aumento de layers, al tener gran cantidad de layers no se genero un aumento de la precision considerable como para generar ese gasto computacional.\n",
        "\n",
        "Despues, en los Modelos CNN, como estos son una mejora de las arquitecturas anteriormente evaluadas, lo que se analizo es su eficiencia y si vale la pena implementarla considerando su gran costo computacional. Aqui se concluyó que hubo un aumento considerable llegando al 92%, siendo este suficientemente superior al 82% obtenido anteriormente, por lo tanto, se puede aceptar el costo computacional que conlleva utilizarlo, este funciona de una manera similar a las redes neuronales, cuanto mas neuronas por layers mejor rendimiento y mayor costo computacional obtenemos.\n",
        "\n",
        "Por ultimo, se evaluo el modelo con otro dataset para analizar el Overfitting y se concluyó que, es un buen modelo en general, ya que, cambiando de dataset obtuvimos una precision del 83%, eso quiere decir que no existe Overfitting y que este Modelo CNN es bueno y se puede utilizar en diferentes dataset.\n"
      ],
      "metadata": {
        "id": "rAa_zFtWl7Bv"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}